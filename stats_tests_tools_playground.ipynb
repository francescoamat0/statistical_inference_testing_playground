{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Statistical tests and tools playground](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- vscode-jupyter-toc --><a id='toc0_'></a>    \n",
    "- [Statistical tests and tools playground](#toc1_)    \n",
    "  - [Import data](#toc1_1_)    \n",
    "  - [Bootstrapping](#toc1_2_)    \n",
    "      - [_Estimate standard error and confidence interval for a given statistic_](#toc1_2_1_1_)    \n",
    "    - [Bootstrap standard error for a statistic](#toc1_2_2_)    \n",
    "    - [Boostrap confidence intervals for a statistic](#toc1_2_3_)    \n",
    "      - [Mean (or other single-sample statistics)](#toc1_2_3_1_)    \n",
    "      - [Corr coefficient](#toc1_2_3_2_)    \n",
    "  - [T-test & Permutation tests](#toc1_3_)    \n",
    "      - [_Comparison between means of 2 groups_](#toc1_3_1_1_)    \n",
    "  - [Bonus: Permutation tests for other multi-sample statistics (eg. corr coefficient)](#toc1_4_)    \n",
    "      - [_Check p-value of multi-sample statistic vs null hypothesis_](#toc1_4_1_1_)    \n",
    "  - [ANOVA & OLS models](#toc1_5_)    \n",
    "      - [_Comparison between means of 3+ groups_](#toc1_5_1_1_)    \n",
    "  - [Proportions tests (Z-test)](#toc1_6_)    \n",
    "      - [_Compare proportions of 2 different groups_](#toc1_6_1_1_)    \n",
    "  - [Chi-square (contigency) tests](#toc1_7_)    \n",
    "      - [_Comparison between the frequencies of multiple groups ('count' data)_](#toc1_7_1_1_)    \n",
    "  - [Exact tests for proportions (Fisher, Barnard, Boschloo)](#toc1_8_)    \n",
    "      - [_Comparison bw frequencies of 2 groups (2x2 contigency tables) with very low sample size_](#toc1_8_1_1_)    \n",
    "  - [Sample size calculations](#toc1_9_)    \n",
    "      - [_Given effect size to be detected and power, solve for sample size of T or Z test_](#toc1_9_1_1_)    \n",
    "  - [Extra infos & links](#toc1_10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats_utils as stats\n",
    "from scipy.stats import bootstrap, permutation_test, ttest_ind, f_oneway, kruskal, alexandergovern, tukey_hsd, pearsonr, chi2_contingency, fisher_exact, barnard_exact, boschloo_exact\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_effectsize\n",
    "from statsmodels.stats.power import tt_ind_solve_power, zt_ind_solve_power\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Import data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some data\n",
    "iris = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
       "0           0    male  22.0                   1      0   7.2500   Third   \n",
       "1           1  female  38.0                   1      0  71.2833   First   \n",
       "2           1  female  26.0                   0      0   7.9250   Third   \n",
       "3           1  female  35.0                   1      0  53.1000   First   \n",
       "4           0    male  28.0                   0      0   8.4583   Third   \n",
       "..        ...     ...   ...                 ...    ...      ...     ...   \n",
       "622         0    male  28.0                   0      0  10.5000  Second   \n",
       "623         0    male  25.0                   0      0   7.0500   Third   \n",
       "624         1  female  19.0                   0      0  30.0000   First   \n",
       "625         0  female  28.0                   1      2  23.4500   Third   \n",
       "626         0    male  32.0                   0      0   7.7500   Third   \n",
       "\n",
       "        deck  embark_town alone  \n",
       "0    unknown  Southampton     n  \n",
       "1          C    Cherbourg     n  \n",
       "2    unknown  Southampton     y  \n",
       "3          C  Southampton     n  \n",
       "4    unknown   Queenstown     y  \n",
       "..       ...          ...   ...  \n",
       "622  unknown  Southampton     y  \n",
       "623  unknown  Southampton     y  \n",
       "624        B  Southampton     y  \n",
       "625  unknown  Southampton     n  \n",
       "626  unknown   Queenstown     y  \n",
       "\n",
       "[627 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some data\n",
    "titanic = pd.read_csv(\n",
    "    'https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "titanic #.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Bootstrapping](#toc0_)\n",
    "#### <a id='toc1_2_1_1_'></a>[_Estimate standard error and confidence interval for a given statistic_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Bootstrap standard error for a statistic](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In modern statistics, the bootstrap has become the standard way to estimate standard error and other accuracy measures for estimators (eg. bias, confidence intervals, etc.). It can be used for virtually any statistic and does not rely on the central limit theorem or other distributional assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function bootstrap_statistic_std_error executed in 9.7193 seconds\n",
      "Bootstrap Statistics:\n",
      "original: 34.385398564593245\n",
      "bias: 0.002295145630114348\n",
      "std. error: 2.1751733214000333\n",
      "std. error with stat approx formula: 2.1804233291368984\n"
     ]
    }
   ],
   "source": [
    "### try out my bootstrapp_statistic_std_error (from utils) ###\n",
    "\n",
    "# df = iris[iris[\"species\"] == \"setosa\"]\n",
    "# column_name = \"sepal_length\"\n",
    "df = titanic\n",
    "column_name = \"fare\"\n",
    "statistic = np.mean\n",
    "\n",
    "original, bias, std_error = stats.bootstrap_statistic_std_error(\n",
    "    df, column_name, statistic, 10000)\n",
    "\n",
    "# print results\n",
    "print('Bootstrap Statistics:')\n",
    "print(f'original: {original}')\n",
    "print(f'bias: {bias}')\n",
    "print(f'std. error: {std_error}')\n",
    "if statistic is np.mean:\n",
    "    # if using 'mean' you can also compute the mathematical approximation of the standard error\n",
    "    std_error_approx = df[column_name].std(\n",
    "    ) / (df[column_name].shape[0] ** (1/2))\n",
    "    print(f'std. error with stat approx formula: {std_error_approx}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error can also be computed using Scipy's bootstrap method (see below for example)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[Boostrap confidence intervals for a statistic](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_3_1_'></a>[Mean (or other single-sample statistics)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function boostrap_statistic_with_confidence_interval executed in 1.5230 seconds\n",
      "\n",
      "Bootstrap Statistics: \n",
      "------------\n",
      "estimate: 34.39326916602862\n",
      "CI lower_bound: 30.27921544657093\n",
      "CI upper_bound: 38.81992862440188 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### try out my boostrap_statistic_with_confidence_interval ###\n",
    "\n",
    "# df = iris[iris[\"species\"] == \"setosa\"]\n",
    "# column_name = \"sepal_length\"\n",
    "df = titanic\n",
    "column_name = \"fare\"\n",
    "statistic = np.mean\n",
    "\n",
    "estimate, lower_bound, upper_bound = stats.boostrap_statistic_with_confidence_interval(\n",
    "    df, column_name, statistic, 0.95, 10000)\n",
    "\n",
    "# print results\n",
    "print('\\nBootstrap Statistics: \\n------------')\n",
    "print(f'estimate: {estimate}')\n",
    "print(f'CI lower_bound: {lower_bound}')\n",
    "print(f'CI upper_bound: {upper_bound} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower (test):  30.085216493418507\n",
      "Upper (test):  38.70132183863873\n"
     ]
    }
   ],
   "source": [
    "# try to get the same CIs by adding/removing 2*(estimated standard error) from the mean\n",
    "    # doesn't yield exactly the same result so be careful when using this approximation (this relies on the normality assumption for the sampling distribution)\n",
    "print(\"Lower (test): \", estimate - 2*std_error)\n",
    "print(\"Upper (test): \", estimate + 2*std_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy CI lower_bound: 30.22956383971292\n",
      "Scipy CI upper_bound: 38.82376676236044\n"
     ]
    }
   ],
   "source": [
    "# compare (also time-wise) to scipy's boostrap method\n",
    "    # which also returns the estimated standard error\n",
    "    # and is about 10x faster :D\n",
    "data = (df[column_name],)\n",
    "res = bootstrap(data, np.mean, confidence_level=0.95, method='percentile', # method can also be 'BCa' (default) and 'basic'\n",
    "                n_resamples=10000)\n",
    "ci_l, ci_u = res.confidence_interval\n",
    "print(f'Scipy CI lower_bound: {ci_l}')\n",
    "print(f'Scipy CI upper_bound: {ci_u}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CI here (with the percentile method) is basically the same as we originally bootstrapped above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_3_2_'></a>[Corr coefficient (or other paired-sample statistics)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    return pearsonr(x, y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfidenceInterval(low=0.05730125741647129, high=0.1919310919951091)\n"
     ]
    }
   ],
   "source": [
    "res = bootstrap((titanic['age'], titanic['fare']), pearson_r, vectorized=False, paired=True, confidence_level=0.95, method='BCa')\n",
    "print(res.confidence_interval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[T-test & Permutation tests](#toc0_)\n",
    "#### <a id='toc1_3_1_1_'></a>[_Comparison between means of 2 groups_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_T-test vs Permutation tests_**\n",
    "\n",
    "An advantage of permutation tests is that they do not require any assumptions about the population parameters, such as the mean or variance, or the distribution of the underlying data. This makes them more robust and generally applicable to a wider range of data. On the other hand, t-tests do require assumptions about the population parameters and on the samples' distribution and variance, which can make them less reliable in certain situations.\n",
    "\n",
    "In addition, Permutation tests exist for any test statistic, regardless of whether or not its distribution is known. Thus one is always free to choose the statistic which best discriminates between hypothesis and alternative and which minimizes losses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try my implementation of a permutation test (from utils):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function permutation_test_statistic_two_groups executed in 7.1684 seconds\n",
      "Observed difference (treatment - control): 0.04813549249740012 \n",
      "p-value: 0.217\n"
     ]
    }
   ],
   "source": [
    "# main example (will be also used below)\n",
    "observed_diff, pvalue = stats.permutation_test_statistic_two_groups(df=titanic, output_col_name=\"n_siblings_spouses\", \n",
    "                                                                  groups_col_name=\"class\", treatment_group_name=\"First\", \n",
    "                                                                  control_group_name=\"Second\",  nrepeat=5000)\n",
    "print(\n",
    "    f\"Observed difference (treatment - control): {observed_diff} \\np-value: {pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function optimised_permutation_test_statistic_two_groups executed in 0.1092 seconds\n",
      "Observed difference (treatment - control): 0.04813549249740012 \n",
      "p-value: 0.27\n"
     ]
    }
   ],
   "source": [
    "# now try again with optimised (vectorised) version of my same function\n",
    "    # compare the execution time! Almost 10x faster\n",
    "observed_diff, pvalue = stats.optimised_permutation_test_statistic_two_groups(df=titanic, output_col_name=\"n_siblings_spouses\", \n",
    "                                                                  groups_col_name=\"class\", treatment_group_name=\"First\", \n",
    "                                                                  control_group_name=\"Second\",  nrepeat=5000)\n",
    "print(\n",
    "    f\"Observed difference (treatment - control): {observed_diff} \\np-value: {pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare against scipy's version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep\n",
    "x, y = titanic.loc[titanic['class'] == 'Second', ['n_siblings_spouses']], titanic.loc[titanic['class'] == 'First', ['n_siblings_spouses']]\n",
    "\n",
    "def statistic(x, y, axis):\n",
    "    # y - x\n",
    "    return np.mean(y, axis=axis) - np.mean(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed difference (y - x): [0.04813549] \n",
      "p-value: [0.27934413]\n"
     ]
    }
   ],
   "source": [
    "# run scipy's perm test\n",
    "    # it executes in roughly 0.1s, so very similar to my optimised implementation!\n",
    "res = permutation_test((x, y), statistic, vectorized=True,\n",
    "                       n_resamples=5000, alternative='greater')\n",
    "print(f\"Observed difference (y - x): {res.statistic} \\np-value: {res.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also plot the resulting null distribution of the test statistic\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(res.null_distribution, bins=50)\n",
    "plt.title(\"Permutation distribution of test statistic\")\n",
    "plt.xlabel(\"Value of Statistic\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare against t-test results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: [0.24960374]\n"
     ]
    }
   ],
   "source": [
    "# t-test assuming no equal variances (Welch’s t-test)\n",
    "t_res = ttest_ind(y, x, equal_var=False, \n",
    "                    permutations=None, alternative='greater')\n",
    "print(f\"p-value: {t_res.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: [0.49920748]\n"
     ]
    }
   ],
   "source": [
    "# two-sided t-test\n",
    "    # -> doubles the smallest p-value bw 'greater' and 'less', so more conservative\n",
    "ts_t_res = ttest_ind(y, x, equal_var=False, \n",
    "                    permutations=None, alternative='two-sided')\n",
    "print(f\"p-value: {ts_t_res.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: [0.25674865]\n"
     ]
    }
   ],
   "source": [
    "# t-test with permutations\n",
    "    # it generates a distribution of the t-statistic under the null hypothesis via permutations, instead of using the t-distribution\n",
    "t_perm_res = ttest_ind(y, x, equal_var=False,\n",
    "                  permutations=5000, alternative='greater')\n",
    "print(f\"p-value: {t_perm_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on the above: an important assumption behind a permutation test is that the observations are exchangeable under the null hypothesis. A consequence of this assumption is that tests of difference in location (like a permutation t-test) require equal variance under the normality assumption. In this respect, the permutation t-test shares the same weakness as the classical Student's t-test (the Behrens–Fisher problem). A third alternative in this situation is to use a bootstrap-based test. Good (2005) explains the difference between permutation tests and bootstrap tests the following way: \"Permutations test hypotheses concerning distributions; bootstraps test hypotheses concerning parameters. As a result, the bootstrap entails less-stringent assumptions.\" Bootstrap tests are not exact. In some cases, a permutation test based on a properly studentized statistic can be asymptotically exact even when the exchangeability assumption is violated. [[6]](https://projecteuclid.org/journals/annals-of-statistics/volume-41/issue-2/Exact-and-asymptotically-robust-permutation-tests/10.1214/13-AOS1090.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power of specified t-test: n_siblings_spouses    0.103442\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We can also check the power of our test given the variables in place!\n",
    "    # Power is the probability that the test correctly rejects the Null Hypothesis if the Alternative Hypothesis is true.\n",
    "\n",
    "effect_size = abs(np.mean(y) - np.mean(x))\n",
    "var_x = np.var(x)\n",
    "var_y = np.var(y)\n",
    "pooled_std = np.sqrt((var_x + var_y) / 2)\n",
    "std_effect_size = effect_size / pooled_std\n",
    "nobs_x = len(x)\n",
    "ratio = len(y) / len(x)\n",
    "\n",
    "t_power = tt_ind_solve_power(effect_size=std_effect_size, nobs1=nobs_x, alpha=0.05, power=None, ratio=ratio, alternative='two-sided')\n",
    "# print(\"Power of specified t-test: {:.1%}\".format(t_power)) #TODO: check why it now throws a formatting error\n",
    "print(f\"Power of specified t-test: {t_power}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try against OLS model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>n_siblings_spouses</td> <th>  R-squared:         </th> <td>   0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>  -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>  0.4504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 09 Jun 2023</td>  <th>  Prob (F-statistic):</th>  <td> 0.503</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>00:35:34</td>      <th>  Log-Likelihood:    </th> <td> -259.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   286</td>       <th>  AIC:               </th> <td>   524.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   284</td>       <th>  BIC:               </th> <td>   531.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.4340</td> <td>    0.048</td> <td>    9.080</td> <td> 0.000</td> <td>    0.340</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Second]</th> <td>   -0.0481</td> <td>    0.072</td> <td>   -0.671</td> <td> 0.503</td> <td>   -0.189</td> <td>    0.093</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>81.249</td> <th>  Durbin-Watson:     </th> <td>   1.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 167.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.445</td> <th>  Prob(JB):          </th> <td>4.75e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.385</td> <th>  Cond. No.          </th> <td>    2.51</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     n_siblings_spouses   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                 -0.002\n",
       "Method:                 Least Squares   F-statistic:                    0.4504\n",
       "Date:                Fri, 09 Jun 2023   Prob (F-statistic):              0.503\n",
       "Time:                        00:35:34   Log-Likelihood:                -259.99\n",
       "No. Observations:                 286   AIC:                             524.0\n",
       "Df Residuals:                     284   BIC:                             531.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.4340      0.048      9.080      0.000       0.340       0.528\n",
       "Q(\"class\")[T.Second]    -0.0481      0.072     -0.671      0.503      -0.189       0.093\n",
       "==============================================================================\n",
       "Omnibus:                       81.249   Durbin-Watson:                   1.874\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              167.275\n",
       "Skew:                           1.445   Prob(JB):                     4.75e-37\n",
       "Kurtosis:                       5.385   Cond. No.                         2.51\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare t-test results vs simple OLS model\n",
    "    # -> the p-value of the class coefficient is (basically) the same as the two-sided t-test results\n",
    "    # -> only difference is that the OLS's t-test assumes equal variances (less precise!)\n",
    "df_ols = titanic[titanic['class'] != 'Third']\n",
    "t_model = ols('n_siblings_spouses ~ Q(\"class\")', data=df_ols).fit()\n",
    "t_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Bonus: Permutation tests for other multi-sample statistics (eg. corr coefficient)](#toc0_)\n",
    "#### <a id='toc1_4_1_1_'></a>[_Check p-value of multi-sample statistic vs null hypothesis_](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    return pearsonr(x, y).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed correlation: 0.11928722927934457 \n",
      "p-value: 0.0018\n"
     ]
    }
   ],
   "source": [
    "# same corr coefficient computed above in the bootstrapping section\n",
    "\n",
    "corr_res = permutation_test((titanic['age'], titanic['fare']), pearson_r, vectorized=False,\n",
    "                       permutation_type='pairings', # This permutation type is appropriate for association/correlation tests with statistics such as Spearman’s , Kendall’s , and Pearson’s .\n",
    "                       alternative='two-sided')\n",
    "# r, pvalue, null = corr_res.statistic, corr_res.pvalue, corr_res.null_distribution\n",
    "print(f\"Observed correlation: {corr_res.statistic} \\np-value: {corr_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[ANOVA & OLS models](#toc0_)\n",
    "#### <a id='toc1_5_1_1_'></a>[_Comparison between means of 3+ groups_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try permutation-ANOVA test for difference of means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed variance of means: 0.013943394715751333 \n",
      "p-value: 0.0653869226154769\n"
     ]
    }
   ],
   "source": [
    "# trying with a permutation-ANOVA test\n",
    "x, y, z = titanic.loc[titanic['class'] == 'First', 'n_siblings_spouses'], titanic.loc[titanic['class'] == 'Second', \n",
    "    'n_siblings_spouses'], titanic.loc[titanic['class'] == 'Third', 'n_siblings_spouses']\n",
    "\n",
    "def anova_statistic(x, y, z):\n",
    "    # var of the groups' means\n",
    "    return np.var([np.mean(x), np.mean(y), np.mean(z)])\n",
    "\n",
    "# run perm test\n",
    "anova_perm_res = permutation_test((x, y, z), anova_statistic, vectorized=False,\n",
    "                       n_resamples=5000, alternative='greater')\n",
    "print(f\"Observed variance of means: {anova_perm_res.statistic} \\np-value: {anova_perm_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try scipy's f_oneway test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.02804501692073304\n"
     ]
    }
   ],
   "source": [
    "# one-way ANOVA F test\n",
    "f_res = f_oneway(x, y, z)\n",
    "print(f\"p-value: {f_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA test has important assumptions that must be satisfied in order for the associated p-value to be valid.\n",
    "\n",
    "- The samples are independent.\n",
    "- Each sample is from a normally distributed population.\n",
    "- The population standard deviations of the groups are all equal. This property is known as homoscedasticity.\n",
    "\n",
    "If these assumptions are not true for a given set of data, it may still be possible to use the Kruskal-Wallis H-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.5985709648385751\n"
     ]
    }
   ],
   "source": [
    "# Compute the Kruskal-Wallis H-test for independent samples.\n",
    "# The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA.\n",
    "kruskal_res = kruskal(x, y, z)\n",
    "print(f\"p-value: {kruskal_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the Alexander Govern test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.014311269992021343\n"
     ]
    }
   ],
   "source": [
    "# The Alexander-Govern approximation tests the equality of k independent means in the face of heterogeneity of variance.\n",
    "\n",
    "# The use of this test still relies on several assumptions.\n",
    "    # The samples are independent.\n",
    "    # Each sample is from a normally distributed population.\n",
    "    # Unlike f_oneway, this test does not assume on homoscedasticity, instead relaxing the assumption of equal variances.\n",
    "\n",
    "alexandergovern_res = alexandergovern(x, y, z)\n",
    "print(f\"p-value: {alexandergovern_res.pvalue}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "although with some loss of power."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-way ANOVA table with OLS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q(\"class\")</th>\n",
       "      <td>9.447149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.594492</td>\n",
       "      <td>0.028045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>820.007397</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq     df         F    PR(>F)\n",
       "Q(\"class\")    9.447149    2.0  3.594492  0.028045\n",
       "Residual    820.007397  624.0       NaN       NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same but expanded results as f_oneway above\n",
    "ow_model = ols('n_siblings_spouses ~ Q(\"class\")', data=titanic).fit()\n",
    "anova_table = sm.stats.anova_lm(ow_model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>n_siblings_spouses</td> <th>  R-squared:         </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   3.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 18 Nov 2022</td>  <th>  Prob (F-statistic):</th>  <td>0.0280</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>15:30:30</td>      <th>  Log-Likelihood:    </th> <td> -973.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   627</td>       <th>  AIC:               </th> <td>   1954.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   624</td>       <th>  BIC:               </th> <td>   1967.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     2</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.4340</td> <td>    0.091</td> <td>    4.773</td> <td> 0.000</td> <td>    0.255</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Second]</th> <td>   -0.0481</td> <td>    0.136</td> <td>   -0.353</td> <td> 0.724</td> <td>   -0.316</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Third]</th>  <td>    0.2229</td> <td>    0.110</td> <td>    2.025</td> <td> 0.043</td> <td>    0.007</td> <td>    0.439</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>502.348</td> <th>  Durbin-Watson:     </th> <td>   2.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8518.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.562</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.593</td>  <th>  Cond. No.          </th> <td>    4.48</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     n_siblings_spouses   R-squared:                       0.011\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     3.594\n",
       "Date:                Fri, 18 Nov 2022   Prob (F-statistic):             0.0280\n",
       "Time:                        15:30:30   Log-Likelihood:                -973.81\n",
       "No. Observations:                 627   AIC:                             1954.\n",
       "Df Residuals:                     624   BIC:                             1967.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.4340      0.091      4.773      0.000       0.255       0.612\n",
       "Q(\"class\")[T.Second]    -0.0481      0.136     -0.353      0.724      -0.316       0.220\n",
       "Q(\"class\")[T.Third]      0.2229      0.110      2.025      0.043       0.007       0.439\n",
       "==============================================================================\n",
       "Omnibus:                      502.348   Durbin-Watson:                   2.093\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8518.282\n",
       "Skew:                           3.562   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.593   Cond. No.                         4.48\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to linear reg output:\n",
    "    # -> PR(>F) in anova table above and Prob(F stat) below, ie the p value of the overall comparison, are the same! (as only 1 indep. variable)\n",
    "    # intercept refers to the \"first\" class\n",
    "ow_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-ways ANOVA table with OLS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q(\"class\")</th>\n",
       "      <td>11.927261</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.566602</td>\n",
       "      <td>0.010744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>6.417293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.913990</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>813.590104</td>\n",
       "      <td>623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq     df         F    PR(>F)\n",
       "Q(\"class\")   11.927261    2.0  4.566602  0.010744\n",
       "sex           6.417293    1.0  4.913990  0.027000\n",
       "Residual    813.590104  623.0       NaN       NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type 2: more power, assumes no significant interaction effect between indep variables\n",
    "tw_model = ols('n_siblings_spouses ~ Q(\"class\") + sex', data=titanic).fit()\n",
    "anova_table = sm.stats.anova_lm(tw_model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>n_siblings_spouses</td> <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   4.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 09 Jun 2023</td>  <th>  Prob (F-statistic):</th>  <td>0.00724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>12:41:14</td>      <th>  Log-Likelihood:    </th> <td> -971.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   627</td>       <th>  AIC:               </th> <td>   1951.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   623</td>       <th>  BIC:               </th> <td>   1968.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    0.5561</td> <td>    0.106</td> <td>    5.243</td> <td> 0.000</td> <td>    0.348</td> <td>    0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Second]</th> <td>   -0.0479</td> <td>    0.136</td> <td>   -0.353</td> <td> 0.725</td> <td>   -0.315</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Third]</th>  <td>    0.2577</td> <td>    0.111</td> <td>    2.325</td> <td> 0.020</td> <td>    0.040</td> <td>    0.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.male]</th>          <td>   -0.2157</td> <td>    0.097</td> <td>   -2.217</td> <td> 0.027</td> <td>   -0.407</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>506.664</td> <th>  Durbin-Watson:     </th> <td>   2.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8794.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.598</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.878</td>  <th>  Cond. No.          </th> <td>    5.25</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     n_siblings_spouses   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                  0.014\n",
       "Method:                 Least Squares   F-statistic:                     4.049\n",
       "Date:                Fri, 09 Jun 2023   Prob (F-statistic):            0.00724\n",
       "Time:                        12:41:14   Log-Likelihood:                -971.34\n",
       "No. Observations:                 627   AIC:                             1951.\n",
       "Df Residuals:                     623   BIC:                             1968.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                0.5561      0.106      5.243      0.000       0.348       0.764\n",
       "Q(\"class\")[T.Second]    -0.0479      0.136     -0.353      0.725      -0.315       0.219\n",
       "Q(\"class\")[T.Third]      0.2577      0.111      2.325      0.020       0.040       0.475\n",
       "sex[T.male]             -0.2157      0.097     -2.217      0.027      -0.407      -0.025\n",
       "==============================================================================\n",
       "Omnibus:                      506.664   Durbin-Watson:                   2.082\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8794.831\n",
       "Skew:                           3.598   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.878   Cond. No.                         5.25\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to linear reg output:\n",
    "    # -> p-value for \"sex\" is the same in both outputs as it has only one level (male). For \"class\" it's more intricate\n",
    "tw_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>20.927536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.973745</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q(\"class\")</th>\n",
       "      <td>4.367950</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.667003</td>\n",
       "      <td>0.189656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.661918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.268523</td>\n",
       "      <td>0.260479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q(\"class\"):sex</th>\n",
       "      <td>0.005071</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.998066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>813.585033</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sum_sq     df          F    PR(>F)\n",
       "Intercept        20.927536    1.0  15.973745  0.000072\n",
       "Q(\"class\")        4.367950    2.0   1.667003  0.189656\n",
       "sex               1.661918    1.0   1.268523  0.260479\n",
       "Q(\"class\"):sex    0.005071    2.0   0.001935  0.998066\n",
       "Residual        813.585033  621.0        NaN       NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type 3 ANOVA: less power, works with interaction effect\n",
    "    # p-value of \"sex\" similar as above, as interaction determined not significant at all\n",
    "tw_model_type3 = ols('n_siblings_spouses ~ Q(\"class\") * sex', data=titanic).fit()\n",
    "anova_table_type3 = sm.stats.anova_lm(tw_model_type3, typ=3)\n",
    "anova_table_type3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>n_siblings_spouses</td> <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   2.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 09 Jun 2023</td>  <th>  Prob (F-statistic):</th>  <td>0.0344</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>13:06:41</td>      <th>  Log-Likelihood:    </th> <td> -971.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   627</td>       <th>  AIC:               </th> <td>   1955.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   621</td>       <th>  BIC:               </th> <td>   1981.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     5</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>    0.5507</td> <td>    0.138</td> <td>    3.997</td> <td> 0.000</td> <td>    0.280</td> <td>    0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Second]</th>             <td>   -0.0416</td> <td>    0.207</td> <td>   -0.201</td> <td> 0.841</td> <td>   -0.448</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Third]</th>              <td>    0.2665</td> <td>    0.182</td> <td>    1.465</td> <td> 0.143</td> <td>   -0.091</td> <td>    0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.male]</th>                      <td>   -0.2063</td> <td>    0.183</td> <td>   -1.126</td> <td> 0.260</td> <td>   -0.566</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Second]:sex[T.male]</th> <td>   -0.0111</td> <td>    0.275</td> <td>   -0.041</td> <td> 0.968</td> <td>   -0.551</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"class\")[T.Third]:sex[T.male]</th>  <td>   -0.0141</td> <td>    0.230</td> <td>   -0.062</td> <td> 0.951</td> <td>   -0.466</td> <td>    0.438</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>506.675</td> <th>  Durbin-Watson:     </th> <td>   2.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8795.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.598</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.879</td>  <th>  Cond. No.          </th> <td>    13.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     n_siblings_spouses   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                  0.011\n",
       "Method:                 Least Squares   F-statistic:                     2.423\n",
       "Date:                Fri, 09 Jun 2023   Prob (F-statistic):             0.0344\n",
       "Time:                        13:06:41   Log-Likelihood:                -971.34\n",
       "No. Observations:                 627   AIC:                             1955.\n",
       "Df Residuals:                     621   BIC:                             1981.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================\n",
       "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                            0.5507      0.138      3.997      0.000       0.280       0.821\n",
       "Q(\"class\")[T.Second]                -0.0416      0.207     -0.201      0.841      -0.448       0.365\n",
       "Q(\"class\")[T.Third]                  0.2665      0.182      1.465      0.143      -0.091       0.624\n",
       "sex[T.male]                         -0.2063      0.183     -1.126      0.260      -0.566       0.153\n",
       "Q(\"class\")[T.Second]:sex[T.male]    -0.0111      0.275     -0.041      0.968      -0.551       0.529\n",
       "Q(\"class\")[T.Third]:sex[T.male]     -0.0141      0.230     -0.062      0.951      -0.466       0.438\n",
       "==============================================================================\n",
       "Omnibus:                      506.675   Durbin-Watson:                   2.082\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8795.430\n",
       "Skew:                           3.598   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.879   Cond. No.                         13.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to linear reg expanded output:\n",
    "    # -> p_value for \"sex\" is the same (as only one level, as above)\n",
    "    # output is broken down more, down to the single levels of each category\n",
    "tw_model_type3.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ANOVA is used to determine whether or not there is a statistically significant difference between the means of three or more independent groups.\n",
    "\n",
    "If the overall p-value from the ANOVA table is less than some significance level, then we have sufficient evidence to say that at least one of the means of the groups is different from the others.\n",
    "\n",
    "However, this doesn’t tell us which groups are different from each other. It simply tells us that not all of the group means are equal. In order to find out exactly which groups are different from each other, we must conduct a post hoc test.\n",
    "\n",
    "One of the most commonly used post hoc tests is Tukey’s Test, which allows us to make pairwise comparisons between the means of each group while controlling for the family-wise error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      " First Second  -0.0481 0.9337 -0.3686 0.2724  False\n",
      " First  Third   0.2229 0.1071 -0.0357 0.4816  False\n",
      "Second  Third   0.2711 0.0602 -0.0089  0.551  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tukey = pairwise_tukeyhsd(endog=titanic['n_siblings_spouses'],\n",
    "                          groups=titanic['class'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "# display results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why can you get a significant result from the ANOVA test and not significant differences in Tukey's HSD?\n",
    "    # https://stats.stackexchange.com/questions/16665/how-can-i-get-a-significant-overall-anova-but-no-significant-pairwise-difference\n",
    "    # https://stats.stackexchange.com/questions/573423/anova-significant-interaction-but-not-significant-post-hoc\n",
    "    # http://www.pmean.com/05/TukeyTest.html\n",
    "\n",
    "    # In short:\n",
    "        # This is mainly due to the sensitivity of ANOVA (greater than the pairwise test sensitivity). \n",
    "        # Then, ANOVA detect lower variability around mean when pairwise test hardly distinguishes between the pair's mean. \n",
    "\n",
    "# (Bonus) On the other hand, do you really need to run a global test (ANOVA) before post-hoc tests?\n",
    "    # https://stats.stackexchange.com/questions/9751/do-we-need-a-global-test-before-post-hoc-tests\n",
    "    # In short: not really, but generally better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
      "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
      " (0 - 1)      0.048     0.934    -0.272     0.369\n",
      " (0 - 2)     -0.223     0.107    -0.482     0.036\n",
      " (1 - 0)     -0.048     0.934    -0.369     0.272\n",
      " (1 - 2)     -0.271     0.060    -0.551     0.009\n",
      " (2 - 0)      0.223     0.107    -0.036     0.482\n",
      " (2 - 1)      0.271     0.060    -0.009     0.551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare to scipy's version\n",
    "    # same result but full matrix\n",
    "hsd_res = tukey_hsd(x, y, z)\n",
    "print(hsd_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the use of Tukey's HSD test relies on several assumptions.\n",
    "\n",
    "- The observations are independent within and among groups.\n",
    "- The observations within each group are normally distributed.\n",
    "- The distributions from which the samples are drawn have the same finite variance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Proportions tests (Z-test)](#toc0_)\n",
    "#### <a id='toc1_6_1_1_'></a>[_Compare proportions of 2 different groups_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Z-test vs Permutation tests_**\n",
    "\n",
    "A z-test for a test of proportions between two groups is used when the following conditions are met:\n",
    "\n",
    "1. Sample size is large enough for z to be approximately normally distributed. Rule of thumb:\n",
    "    - Significance test: number of successes and number of failures are each 5 or more in both sample groups\n",
    "    - Regular (large sample) 90%, 95%, or 99% confidence interval: number of successes and number of failures are each 10 or more in both sample groups\n",
    "    - Plus four 90%, 95%, or 99% confidence interval: sample sizes of both groups are 5 or more\n",
    "2. Group 1 sample is a simple random sample (SRS) from population 1, group 2 sample is an independent SRS from population 2. That is, within and between groups, observations are independent of one another.\n",
    "\n",
    "A permutation test, on the other hand, does not require any assumptions about the underlying distribution of the data and can be used with smaller sample sizes. It works by simulating the sampling process many times and computing the test statistic for each simulated sample. The p-value is then calculated as the fraction of simulated samples that have a test statistic that is at least as extreme as the one observed in the actual data. If the above conditions are not met, you should use instead a permutation test.\n",
    "\n",
    "However, a permutation test is generally less powerful than a z-test or a chi-square test, so it may not be able to detect small differences between the means or proportions of the two groups. In addition, a permutation test can be computationally intensive, especially for large sample sizes, so it may not be practical in some situations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Z-test vs Chi-square test_**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Z-test is used when comparing the difference in population proportions between 2 groups. \n",
    "- The Chi-square test is used when comparing the difference in population proportions between 2 or more groups or when comparing a group with a value.\n",
    "\n",
    "A chi-square test for equality of two proportions is exactly the same thing as a z-test. The chi-squared distribution with one degree of freedom is just that of a normal deviate, squared. You're basically just repeating the chi-squared test on a subset of the contingency table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.159\n"
     ]
    }
   ],
   "source": [
    "# Using Z-test \n",
    "    # better than T-test when working with proportions since the standard deviation is known \n",
    "    # (standard deviation of a proportion is a function of the proportion itself)\n",
    "\n",
    "count_positives = np.array([5, 12])\n",
    "nobs_tot = np.array([83, 99])\n",
    "\n",
    "stat, pval = proportions_ztest(count_positives, nobs_tot, alternative='two-sided')\n",
    "print('P-value: {0:0.3f}'.format(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in proportions is not statistically significant.\n",
      "The 95% confidence interval for the difference in proportions is (-0.203, 0.103)\n"
     ]
    }
   ],
   "source": [
    "# trial from chatGPT\n",
    "    # same thing, plus it's computing the 95% CI\n",
    "\n",
    "# import the necessary libraries\n",
    "from scipy.stats import norm # rest already imported\n",
    "\n",
    "# define the sample sizes and number of successes for each group\n",
    "n1 = 100\n",
    "n2 = 50\n",
    "successes1 = 25\n",
    "successes2 = 15\n",
    "\n",
    "# calculate the proportions for each group\n",
    "prop1 = successes1 / n1\n",
    "prop2 = successes2 / n2\n",
    "\n",
    "# compute the test statistic and p-value using the proportions_ztest function\n",
    "z_stat, pval = proportions_ztest([successes1, successes2], [n1, n2], alternative='two-sided')\n",
    "\n",
    "# interpret the results\n",
    "if pval < 0.05:\n",
    "    print(\"The difference in proportions is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in proportions is not statistically significant.\")\n",
    "\n",
    "# compute the 95% confidence interval for the difference in proportions\n",
    "pdiff = prop1 - prop2\n",
    "z_critical = norm.ppf(0.975)  # get the critical value of the normal distribution at 95% confidence\n",
    "low, high = pdiff - z_critical * np.sqrt(prop1 * (1 - prop1) / n1 + prop2 * (1 - prop2) / n2), pdiff + z_critical * np.sqrt(prop1 * (1 - prop1) / n1 + prop2 * (1 - prop2) / n2)\n",
    "print(\"The 95% confidence interval for the difference in proportions is ({:.3f}, {:.3f})\".format(low, high))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Chi-square (contigency) tests](#toc0_)\n",
    "#### <a id='toc1_7_1_1_'></a>[_Comparison between the frequencies of multiple groups ('count' data)_](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          group_a  group_b  group_c\n",
      "click          15       10       25\n",
      "no_click       40       20       30\n"
     ]
    }
   ],
   "source": [
    "# A made-up example for Scipy's method\n",
    "obs = np.array([[15, 10, 25], [40, 20, 30]])\n",
    "\n",
    "index_values = ['click', 'no_click']\n",
    "column_values = ['group_a', 'group_b', 'group_c']\n",
    "df_obs = pd.DataFrame(data=obs,\n",
    "                      index=index_values,\n",
    "                      columns=column_values)\n",
    "print(df_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value:  0.1317385467621491\n"
     ]
    }
   ],
   "source": [
    "g, p, dof, expctd = chi2_contingency(df_obs)\n",
    "print(\"P-value: \", p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Exact tests for proportions (Fisher, Barnard, Boschloo)](#toc0_)\n",
    "#### <a id='toc1_8_1_1_'></a>[_Comparison bw frequencies of 2 groups (2x2 contigency tables) with very low sample size_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-square distribution or z-test are a good approximation of the shuffled resampling test, except when counts are extremely low (single digits, especially five or fewer). In such cases, the resampling procedure will yield more accurate p-values. \n",
    "\n",
    "In fact, most statistical software has a procedure to actually enumerate all the possible rearrangements (permutations) that can occur, tabulate their frequencies, and determine exactly how extreme the observed result is. This is called Fisher’s exact test after the great statistician R. A. Fisher.\n",
    "\n",
    "In addition, more recent tests such as \"Barnard exact\" and \"Boschloo exact\" are more powerful than Fisher's.\n",
    "\n",
    "Note, however, that many packages provide the results of these exact tests for 2 × 2 contingency tables but not for bigger contingency tables with more rows or columns. For Fisher's exact test of bigger contingency tables, we can use web pages providing such analyses. For example, the web page ‘Social Science Statistics’ (http://www.socscistatistics.com/tests/chisquare2/Default2.aspx) permits performance of Fisher exact test for up to 5 × 5 contingency tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fischer p-value:  0.6219813684237752\n",
      "Barnard p-value:  0.6124696915520649\n",
      "Boschloo p-value:  0.5721916140286106\n"
     ]
    }
   ],
   "source": [
    "# These exact tests only work on 2x2 contigency tables\n",
    "df_obs_cut = df_obs[['group_a', 'group_b']]\n",
    "\n",
    "_, fisher_p = fisher_exact(df_obs_cut, alternative='two-sided')\n",
    "barnard_p = barnard_exact(df_obs_cut, alternative=\"two-sided\").pvalue\n",
    "boschloo_p = boschloo_exact(df_obs_cut, alternative=\"two-sided\").pvalue\n",
    "\n",
    "print(\"Fischer p-value: \", fisher_p)\n",
    "print(\"Barnard p-value: \", barnard_p)\n",
    "print(\"Boschloo p-value: \", boschloo_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[Sample size calculations](#toc0_)\n",
    "#### <a id='toc1_9_1_1_'></a>[_Given effect size to be detected and power, solve for sample size of T or Z test_](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_T-Test between means:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size required to detect the specified std effect size of 0.10: \n",
      "1570.73 \n",
      "(for each group)\n"
     ]
    }
   ],
   "source": [
    "# Sample size is sensitive to the size and variability of the difference between groups, and tolerance to Type I and II errors.\n",
    "\n",
    "mean_diff = 0.1\n",
    "sd_diff = 1 # the st.dev of the difference or the pooled standard deviation of the 2 samples\n",
    "std_effect_size = mean_diff / sd_diff # standardized effect size, difference between the two means divided by the standard deviation. It has to be positive.\n",
    "\n",
    "means_sample_size = tt_ind_solve_power(effect_size=std_effect_size, nobs1=None, alpha=0.05, \n",
    "                                        power=0.8, ratio=1.0, alternative='two-sided')\n",
    "print(\n",
    "    \"Sample size required to detect the specified std effect size of {:.2f}: \\n{:.2f} \\n(for each group)\".format(std_effect_size, means_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number in *each* group when SD is 0.4 : 252.13\n",
      "Number in *each* group when SD is 0.8 : 1005.62\n",
      "Number in *each* group when SD is 1.6 : 4019.58\n"
     ]
    }
   ],
   "source": [
    "# It is easy to see that changes in the standardised mean difference we want to detect will change the sample size. \n",
    "# For example, for a mean difference of 0.1 as above, sample size increases significantly as standard deviation of the difference increases:\n",
    "\n",
    "for sd in [0.4, 0.8, 1.6]:\n",
    "    n = tt_ind_solve_power(effect_size=mean_diff/sd, alpha=0.05,\n",
    "                           power=0.8, ratio=1, alternative='two-sided')\n",
    "    print('Number in *each* group when SD is {:<4.1f}: {:.2f}'.format(sd, n))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Z-Test between proportions:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size required to detect the specified difference in proportions: \n",
      "76.65 \n",
      "(for each group)\n"
     ]
    }
   ],
   "source": [
    "# define the 2 proportions:\n",
    "prop1 = 0.5\n",
    "prop2 = 0.75\n",
    "\n",
    "# compute effect size and required sample size\n",
    "es = proportion_effectsize(prop1=prop1, prop2=prop2)\n",
    "prop_sample_size = zt_ind_solve_power(effect_size=es, nobs1=None, alpha=0.05, power=0.9, ratio=1.0, alternative='two-sided')\n",
    "print(\"Sample size required to detect the specified difference in proportions: \\n{:.2f} \\n(for each group)\".format(prop_sample_size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_10_'></a>[Extra infos & links](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are regression, the t-test, and the ANOVA all versions of the general linear model?\n",
    "- https://stats.stackexchange.com/questions/59047/how-are-regression-the-t-test-and-the-anova-all-versions-of-the-general-linear\n",
    "- https://www.researchgate.net/post/Can-anyone-help-me-to-get-the-core-differences-between-regression-model-and-ANOVA-model#view=54f420f5d685cc07258b46ea\n",
    "- https://stats.stackexchange.com/questions/175246/why-is-anova-equivalent-to-linear-regression\n",
    "\n",
    "From the mathematical point of view, linear regression and ANOVA are identical: both break down the total variance of the data into different “portions” and verify the equality of these “sub-variances” by means of a test (“F” Test). What can be added is that, in both techniques the dependent variable is a continuous one, but in the ANOVA analysis the independent variable can be exclusively categorical variable, while in the regression can be used both categorical and continuous independent variables. Thus, ANOVA can be considered as a case of a linear regression in which all predictors are categorical.\n",
    "- https://www.statsimprove.com/en/what-is-the-difference-between-anova-and-regression-and-which-one-to-choose/\n",
    "\n",
    "If the categorical predictor has only 2 levels such as sex (male, female), then the simple regression analysis is equivalent to an independent t test. If the single categorical variable has more than 2 levels, then the simple linear regression is equivalent to 1-way analysis of variance (ANOVA). If we have 2 categorical predictor variables with 2 or more levels, linear regression is equivalent to 2-way or a higher level of ANOVA. This flexibility of the regression models allows us to perform most analyses using a unified approach. Using linear regression instead of a t test or ANOVA allows us to directly obtain estimates (differences between treatment groups) along with their confidence intervals instead of only P values.\n",
    "- https://www.ajodo.org/article/S0889-5406(16)00087-1/fulltext#relatedArticles\n",
    "\n",
    "The main benefit of ANOVA ovethe r regression, in my opinion, is in the output. If you are interested in the statistical significance of the categorical variable (factor) as a block, then ANOVA provides this test for you. With regression, the categorical variable is represented by 2 or more dummy variables, depending on the number of categories, and hence you have 2 or more statistical tests, each comparing the mean for the particular category against the mean of the null category (or the overall mean, depending on dummy coding method). Neither of these may be of interest. Thus, you must perform post-estimation analysis (essentially, ANOVA) to get the overall test of the factor that you are interested in.\n",
    "- https://stats.stackexchange.com/questions/190984/anova-vs-multiple-linear-regression-why-is-anova-so-commonly-used-in-experiment/191141#191141\n",
    "\n",
    "When to use the z-test (proportions) vs t-tests (means)?\n",
    "- https://bloomingtontutors.com/blog/when-to-use-the-z-test-versus-t-test\n",
    "\n",
    "The usual one and two-sample proportions tests are of this form, and thus we have some justification for treating them as asymptotically normal, but we have no justification for treating them as t-distributed.\n",
    "In practice, as long as np and n(1−p) are not too small**, the asymptotic normality of the one and two-sample proportions tests comes in very rapidly (that is, often surprisingly small n is enough for both theorems to 'kick in' as it were and the asymptotic behavior to be a good approximation to small sample behavior).\n",
    "- https://stats.stackexchange.com/questions/90893/why-use-a-z-test-rather-than-a-t-test-with-proportional-data\n",
    "\n",
    "Is there a minimum sample size required for the t-test to be valid?\n",
    "Historically, the very first demonstration of the t-test (in \"Student\"'s 1908 paper) was in an application to sample sizes of size four. Indeed, obtaining improved results for small samples is the test's claim to fame: once the sample size reaches 40 or so, the t-test is not substantially different from the z-tests researchers had been applying throughout the 19th century. \n",
    "- https://stats.stackexchange.com/questions/37993/is-there-a-minimum-sample-size-required-for-the-t-test-to-be-valid\n",
    "- ...but you do have Power concerns when doing t-tests on small samples sizes. \n",
    "Eg. the statistical power for a sample size of 15, a one-sample t-test, standard α=.05, and three different effect sizes of .2, .5, .8 (which have sometimes been referred to as small, medium, and large effects respectively) are 11%, 44% and 82% respectively. Only the last one could be said to be \"reasonable\" power.\n",
    "\n",
    "Is there a minimum sample size for bootstrapping to be valid?\n",
    "In short: not really, it can work even for small sample sizes (eg. 20 obs); if they’re not unreasonably small (eg. 4)\n",
    "- https://stats.stackexchange.com/questions/33300/determining-sample-size-necessary-for-bootstrap-method-proposed-method\n",
    "\n",
    "Power Analysis For Sample Size Using Python\n",
    "- https://grabngoinfo.com/power-analysis-for-sample-size-using-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3631da6e567c4e4e96f23f748a2e4cfe13530ca02004e1c751df61e5691c91db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
